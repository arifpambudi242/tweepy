{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe51ef51",
   "metadata": {},
   "source": [
    "### 1.Install Library(module) yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136490e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %pip install tweepy\n",
    "# %pip install Sastrawi\n",
    "# %pip install numpy\n",
    "# %pip install sklearn\n",
    "# %pip install textblob\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f81aea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARERTOKEN = 'AAAAAAAAAAAAAAAAAAAAAJQrYQEAAAAA1BtlexYIrHRZvqkz6TEOraEC%2B0k%3D5cOp6U7ytEMpcTDctDQWVl6HFd0Y28pxhDnTGyHA9KiiC1MVCF'\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARERTOKEN)\n",
    "\n",
    "query = '\"Jokowi 3 priode\" lang:id'\n",
    "\n",
    "# get data max 100\n",
    "responses = client.search_recent_tweets(query=query, max_results=100, tweet_fields=['created_at'])\n",
    "tweet100 = [tweet for tweet in responses.data]\n",
    "\n",
    "# get max 1000\n",
    "tweettexts = [tweet.text for tweet in tweepy.Paginator(client.search_recent_tweets, query=query, max_results=100).flatten(limit=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4edee1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fece5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'text' : tweettexts\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"crawling.csv\", mode='w', index=False, header=data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa7fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Nandaa_80 @sandiuno Tugasnya mempromosikan jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @yani_akhmad: @geloraco Rencana buat Pilpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@geloraco Rencana buat Pilpres 2024 Jokowi 3 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @SakiinaQhiCO_33: Sebuah kewajaran dan sah\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @SakiinaQhiCO_33: Sebuah kewajaran dan sah\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @Nandaa_80 @sandiuno Tugasnya mempromosikan jo...\n",
       "1  RT @yani_akhmad: @geloraco Rencana buat Pilpre...\n",
       "2  @geloraco Rencana buat Pilpres 2024 Jokowi 3 p...\n",
       "3  RT @SakiinaQhiCO_33: Sebuah kewajaran dan sah\"...\n",
       "4  RT @SakiinaQhiCO_33: Sebuah kewajaran dan sah\"..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('crawling.csv', encoding='unicode_escape')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2058c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text\n",
    "def textcleaner(text):\n",
    "    new_text = str(text)\n",
    "    \n",
    "    # remove old style retweet text \"RT\"\n",
    "    new_text = re.sub(r'^RT\\s+', '', new_text)\n",
    "    \n",
    "    # remove username\n",
    "    new_text = re.sub(r'@([A-Za-z0-9_]+)', '', new_text)\n",
    "\n",
    "    # remove hyperlinks\n",
    "    new_text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', new_text)\n",
    "\n",
    "    # remove invalid character\n",
    "    new_text = re.sub(\"[^A-Za-z\" \"]+\", \" \", new_text)\n",
    "    \n",
    "    new_text    = re.sub(r'\\b\\w(1,2)\\b',' ', new_text) #menghilangkan 2 kata\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8447bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caselower(sentences):\n",
    "    return sentences.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602e90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenmaker(sentences):\n",
    "    return sentences.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b28e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Removal\n",
    "stopword = nltk.corpus.stopwords.words(\"indonesian\")\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be246c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05eeef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labeler\n",
    "\n",
    "pos_kata = [pos.strip() for pos in open('kata_positif.txt', 'r').readlines()]\n",
    "neg_kata = [neg.strip() for neg in open('kata_negatif.txt', 'r').readlines()]\n",
    "\n",
    "#list kata-kata negasi\n",
    "negasi = [neg.strip() for neg in open('negasi.txt', 'r').readlines()]\n",
    "\n",
    "\n",
    "def labeling(stemmed):\n",
    "    count_pos = 0\n",
    "    count_neg = 0\n",
    "    for ind, stem in enumerate(stemmed):\n",
    "        if stem.strip() in pos_kata:\n",
    "            if stemmed[ind-1].strip() in negasi:\n",
    "                count_neg += 1\n",
    "            else:\n",
    "                count_pos += 1\n",
    "        elif stem.strip() in neg_kata:\n",
    "            if stemmed[ind-1].strip() in negasi:\n",
    "                count_pos += 1\n",
    "            else:\n",
    "                count_neg += 1\n",
    "\n",
    "    return 'NETRAL' if count_pos == count_neg else 'POSITIF' if count_pos > count_neg else 'NEGATIF'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b013e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text\n",
    "df['clean_text'] = df['text'].apply(lambda x : textcleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067846e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cover ke lower case\n",
    "df['lower'] = df['clean_text'].apply(lambda x : caselower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f02b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "df['token'] = df['lower'].apply(lambda x : tokenmaker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "074e5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword removing\n",
    "df[\"stop_removed\"] = df['token'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56bfe6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming selesai!\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "df[\"stemmed\"] = df['stop_removed'].apply(lambda x: stemming(x))\n",
    "print(\"Stemming selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a27497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling sentiment\n",
    "df[\"sentiment\"] = df['stemmed'].apply(lambda x: labeling(x))\n",
    "df.to_csv(f\"labeled.csv\", mode='w', index=False, header=False)\n",
    "df.head(df.size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcf67f61d93bb807738c728a2d36bcd352b61f91fdc0746bde934977bba04043"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
