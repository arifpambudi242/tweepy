{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd9ca35",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analisys menggunakan metode A NAIVE BAYES CLASSIFIER (NBC)\n",
    "### 1.Case Folding:\n",
    "Case folding dilakukan untuk\n",
    "mengubah setiap karakter didalam teks menjadi huruf\n",
    "kecil. Tidak semua kata dalam teks konsisten dalam\n",
    "penggunaan huruf kapital disinilah tujuan dilakukan case\n",
    "folding untuk mengkonversi setiap karakter dalam kata\n",
    "menjadi huruf kecil.\n",
    "### 2.Tokenisasi: \n",
    "Tokenisasi merupakan proses\n",
    "pemecahan kata pada suatu teks ke dalam satuan kata.\n",
    "Tokenisasi dilakukan untuk menghasilkan kumpulan kata\n",
    "yang berdiri sendiri, tokenisasi memecah teks yang\n",
    "semula berupa kalimat menjadi kata-kata. tokenisasi\n",
    "menghilangkan delimeter seperti titik (.), koma (,), spasi,\n",
    "dan karakter angka yang ada pada kata tersebut.\n",
    "Dalam penelitian ini tokenisasi dilakukan untuk\n",
    "memecah kata, serta melakukan penghapusan delimeter\n",
    "beserta karakter angka bersama tweet entity seperti\n",
    "hashtag, retweet dan mention.\n",
    "### 3.Filtering: \n",
    "Filtering merupakan proses dalam text\n",
    "preprocessing setelah tokenisasi, filtering dilakukan untuk\n",
    "untuk mengambil kata penting hasil tokenisasi. Pada tahap\n",
    "filtering kata akan ditentukan apakah akan digunakan atau \n",
    "dibuang. Proses dalam filtering dalam membuang katakata yang tidak digunakan atau stopword terdapat dalam\n",
    "bag of words stoplist.\n",
    "Stopword merupakan daftar kata-kata yang tidak\n",
    "mempresentasikan isi dari suatu dokumen teks, stopword\n",
    "dilakukan untuk meghilangkan kata atau term yang tidak\n",
    "memiliki arti. Daftar stoplist akan dibuat sebelum\n",
    "melakukan proses stopword removal, jika kata-kata\n",
    "terdapat dalam daftar stoplist, maka kata tersebut akan\n",
    "dihapus, sehingga kata-kata yang tersisa akan dianggap\n",
    "kata yang mencirikan isi suatu dokumen.\n",
    "### 4.Stemming: \n",
    "Stemming merupakan proses mengubah\n",
    "kata menjadi bentuk dasarnya. Stemming dilakukan untuk\n",
    "meyeragamkan bentuk kata. Tujuan dari proses stemming\n",
    "adalah menghilangkan imbuhan-imbuhan baik itu berupa\n",
    "prefiks, sufiks, maupun konfiks yang ada pada setiap kata. \n",
    "Stemming dalam penelitian ini dilakukan berdasarkan\n",
    "aturan morfologi bahasa Indonesia.\n",
    "\n",
    "\n",
    "### berikut adalah langka-langkahnya:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51ef51",
   "metadata": {},
   "source": [
    "### 1.Install Library(module) yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136490e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %pip install tweepy\n",
    "# %pip install Sastrawi\n",
    "# %pip install numpy\n",
    "# %pip install sklearn\n",
    "# %pip install textblob\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81aea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARERTOKEN = 'AAAAAAAAAAAAAAAAAAAAAJQrYQEAAAAA1BtlexYIrHRZvqkz6TEOraEC%2B0k%3D5cOp6U7ytEMpcTDctDQWVl6HFd0Y28pxhDnTGyHA9KiiC1MVCF'\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARERTOKEN)\n",
    "\n",
    "query = '\"Ruang Guru\" lang:id'\n",
    "\n",
    "# get data max 100\n",
    "responses = client.search_recent_tweets(query=query, max_results=100, tweet_fields=['created_at'])\n",
    "tweet100 = [tweet for tweet in responses.data]\n",
    "\n",
    "# get max 1000\n",
    "tweettexts = [tweet.text for tweet in tweepy.Paginator(client.search_recent_tweets, query=query, max_results=100).flatten(limit=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4edee1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fece5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweettexts = [tweet.lower() for tweet in tweettexts]\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "    'text' : tweettexts\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"crawling{datetime.today().strftime('%Y-%m-%d')}.csv\", mode='w', index=False, header=data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa7fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Muhisammy: @Androngehe @worksfess Sama kek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RamenTerbang: @worksfess jangankan nakes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@gapyearfess Ruang guru , zenius sama bimbel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jinniesteacher Kebalik kak..maksud dia. Murid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RamenTerbang: @worksfess jangankan nakes, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @Muhisammy: @Androngehe @worksfess Sama kek...\n",
       "1  RT @RamenTerbang: @worksfess jangankan nakes, ...\n",
       "2  @gapyearfess Ruang guru , zenius sama bimbel a...\n",
       "3  @jinniesteacher Kebalik kak..maksud dia. Murid...\n",
       "4  RT @RamenTerbang: @worksfess jangankan nakes, ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('crawling2022-06-03.csv', encoding='unicode_escape')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2058c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text\n",
    "def textcleaner(text):\n",
    "    new_text = str(text)\n",
    "    \n",
    "    # remove old style retweet text \"RT\"\n",
    "    new_text = re.sub(r'^RT\\s+', '', new_text)\n",
    "    \n",
    "    # remove username\n",
    "    new_text = re.sub(r'@([A-Za-z0-9_]+)', '', new_text)\n",
    "\n",
    "    # remove hyperlinks\n",
    "    new_text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', new_text)\n",
    "\n",
    "    # remove invalid character\n",
    "    new_text = re.sub(\"[^A-Za-z\" \"]+\", \" \", new_text)\n",
    "    \n",
    "    new_text    = re.sub(r'\\b\\w(1,2)\\b',' ', new_text) #menghilangkan 2 kata\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8447bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caselower(sentences):\n",
    "    return sentences.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602e90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenmaker(sentences):\n",
    "    return sentences.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b28e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Removal\n",
    "stopword = nltk.corpus.stopwords.words(\"indonesian\")\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be246c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b013e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text\n",
    "df['clean_text'] = df['text'].apply(lambda x : textcleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "067846e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cover ke lower case\n",
    "df['lower'] = df['clean_text'].apply(lambda x : caselower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f02b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "df['token'] = df['lower'].apply(lambda x : tokenmaker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "074e5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword removing\n",
    "df[\"stop_removed\"] = df['token'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56bfe6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming selesai!\n"
     ]
    }
   ],
   "source": [
    "# stemming removing\n",
    "df[\"stemmed\"] = df['stop_removed'].apply(lambda x: stemming(x))\n",
    "print(\"Stemming selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d895855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>token</th>\n",
       "      <th>lower</th>\n",
       "      <th>stop_removed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Muhisammy: @Androngehe @worksfess Sama kek...</td>\n",
       "      <td>Sama kek guru itu julidin murid termasuk cara...</td>\n",
       "      <td>[sama, kek, guru, itu, julidin, murid, termasu...</td>\n",
       "      <td>sama kek guru itu julidin murid termasuk cara...</td>\n",
       "      <td>[kek, guru, julidin, murid, penyelesaiannya, r...</td>\n",
       "      <td>[kek, guru, julidin, murid, selesai, ruang, gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RamenTerbang: @worksfess jangankan nakes, ...</td>\n",
       "      <td>jangankan nakes murid julidin gurunya aja uda...</td>\n",
       "      <td>[jangankan, nakes, murid, julidin, gurunya, aj...</td>\n",
       "      <td>jangankan nakes murid julidin gurunya aja uda...</td>\n",
       "      <td>[nakes, murid, julidin, gurunya, aja, udah, yg...</td>\n",
       "      <td>[nakes, murid, julidin, guru, aja, udah, yg, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@gapyearfess Ruang guru , zenius sama bimbel a...</td>\n",
       "      <td>Ruang guru zenius sama bimbel area eksak</td>\n",
       "      <td>[ruang, guru, zenius, sama, bimbel, area, eksak]</td>\n",
       "      <td>ruang guru zenius sama bimbel area eksak</td>\n",
       "      <td>[ruang, guru, zenius, bimbel, area, eksak]</td>\n",
       "      <td>[ruang, guru, zenius, bimbel, area, eksak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jinniesteacher Kebalik kak..maksud dia. Murid...</td>\n",
       "      <td>Kebalik kak maksud dia Murid julidin guru Cum...</td>\n",
       "      <td>[kebalik, kak, maksud, dia, murid, julidin, gu...</td>\n",
       "      <td>kebalik kak maksud dia murid julidin guru cum...</td>\n",
       "      <td>[kebalik, kak, maksud, murid, julidin, guru, c...</td>\n",
       "      <td>[balik, kak, maksud, murid, julidin, guru, cum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @RamenTerbang: @worksfess jangankan nakes, ...</td>\n",
       "      <td>jangankan nakes murid julidin gurunya aja uda...</td>\n",
       "      <td>[jangankan, nakes, murid, julidin, gurunya, aj...</td>\n",
       "      <td>jangankan nakes murid julidin gurunya aja uda...</td>\n",
       "      <td>[nakes, murid, julidin, gurunya, aja, udah, yg...</td>\n",
       "      <td>[nakes, murid, julidin, guru, aja, udah, yg, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>RT @middleclassthud: suka banget ama lagunya l...</td>\n",
       "      <td>suka banget ama lagunya letto yang ruang guru</td>\n",
       "      <td>[suka, banget, ama, lagunya, letto, yang, ruan...</td>\n",
       "      <td>suka banget ama lagunya letto yang ruang guru</td>\n",
       "      <td>[suka, banget, ama, lagunya, letto, ruang, guru]</td>\n",
       "      <td>[suka, banget, ama, lagu, letto, ruang, guru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>RT @donhae: @AREAJULID kalo di negeriâ¦ awikw...</td>\n",
       "      <td>kalo di negeri awikwok banget dah isinya kerj...</td>\n",
       "      <td>[kalo, di, negeri, awikwok, banget, dah, isiny...</td>\n",
       "      <td>kalo di negeri awikwok banget dah isinya kerj...</td>\n",
       "      <td>[kalo, negeri, awikwok, banget, dah, isinya, k...</td>\n",
       "      <td>[kalo, negeri, awikwok, banget, dah, isi, kerj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>RT @middleclassthud: suka banget ama lagunya l...</td>\n",
       "      <td>suka banget ama lagunya letto yang ruang guru</td>\n",
       "      <td>[suka, banget, ama, lagunya, letto, yang, ruan...</td>\n",
       "      <td>suka banget ama lagunya letto yang ruang guru</td>\n",
       "      <td>[suka, banget, ama, lagunya, letto, ruang, guru]</td>\n",
       "      <td>[suka, banget, ama, lagu, letto, ruang, guru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@moonareas ruang guruð­ð­ð­ð­ð­</td>\n",
       "      <td>ruang guru</td>\n",
       "      <td>[ruang, guru]</td>\n",
       "      <td>ruang guru</td>\n",
       "      <td>[ruang, guru]</td>\n",
       "      <td>[ruang, guru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>RT @middleclassthud: suka banget ama lagunya l...</td>\n",
       "      <td>suka banget ama lagunya letto yang ruang guru</td>\n",
       "      <td>[suka, banget, ama, lagunya, letto, yang, ruan...</td>\n",
       "      <td>suka banget ama lagunya letto yang ruang guru</td>\n",
       "      <td>[suka, banget, ama, lagunya, letto, ruang, guru]</td>\n",
       "      <td>[suka, banget, ama, lagu, letto, ruang, guru]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    RT @Muhisammy: @Androngehe @worksfess Sama kek...   \n",
       "1    RT @RamenTerbang: @worksfess jangankan nakes, ...   \n",
       "2    @gapyearfess Ruang guru , zenius sama bimbel a...   \n",
       "3    @jinniesteacher Kebalik kak..maksud dia. Murid...   \n",
       "4    RT @RamenTerbang: @worksfess jangankan nakes, ...   \n",
       "..                                                 ...   \n",
       "995  RT @middleclassthud: suka banget ama lagunya l...   \n",
       "996  RT @donhae: @AREAJULID kalo di negeriâ¦ awikw...   \n",
       "997  RT @middleclassthud: suka banget ama lagunya l...   \n",
       "998          @moonareas ruang guruð­ð­ð­ð­ð­   \n",
       "999  RT @middleclassthud: suka banget ama lagunya l...   \n",
       "\n",
       "                                            clean_text  \\\n",
       "0     Sama kek guru itu julidin murid termasuk cara...   \n",
       "1     jangankan nakes murid julidin gurunya aja uda...   \n",
       "2             Ruang guru zenius sama bimbel area eksak   \n",
       "3     Kebalik kak maksud dia Murid julidin guru Cum...   \n",
       "4     jangankan nakes murid julidin gurunya aja uda...   \n",
       "..                                                 ...   \n",
       "995      suka banget ama lagunya letto yang ruang guru   \n",
       "996   kalo di negeri awikwok banget dah isinya kerj...   \n",
       "997      suka banget ama lagunya letto yang ruang guru   \n",
       "998                                        ruang guru    \n",
       "999      suka banget ama lagunya letto yang ruang guru   \n",
       "\n",
       "                                                 token  \\\n",
       "0    [sama, kek, guru, itu, julidin, murid, termasu...   \n",
       "1    [jangankan, nakes, murid, julidin, gurunya, aj...   \n",
       "2     [ruang, guru, zenius, sama, bimbel, area, eksak]   \n",
       "3    [kebalik, kak, maksud, dia, murid, julidin, gu...   \n",
       "4    [jangankan, nakes, murid, julidin, gurunya, aj...   \n",
       "..                                                 ...   \n",
       "995  [suka, banget, ama, lagunya, letto, yang, ruan...   \n",
       "996  [kalo, di, negeri, awikwok, banget, dah, isiny...   \n",
       "997  [suka, banget, ama, lagunya, letto, yang, ruan...   \n",
       "998                                      [ruang, guru]   \n",
       "999  [suka, banget, ama, lagunya, letto, yang, ruan...   \n",
       "\n",
       "                                                 lower  \\\n",
       "0     sama kek guru itu julidin murid termasuk cara...   \n",
       "1     jangankan nakes murid julidin gurunya aja uda...   \n",
       "2             ruang guru zenius sama bimbel area eksak   \n",
       "3     kebalik kak maksud dia murid julidin guru cum...   \n",
       "4     jangankan nakes murid julidin gurunya aja uda...   \n",
       "..                                                 ...   \n",
       "995      suka banget ama lagunya letto yang ruang guru   \n",
       "996   kalo di negeri awikwok banget dah isinya kerj...   \n",
       "997      suka banget ama lagunya letto yang ruang guru   \n",
       "998                                        ruang guru    \n",
       "999      suka banget ama lagunya letto yang ruang guru   \n",
       "\n",
       "                                          stop_removed  \\\n",
       "0    [kek, guru, julidin, murid, penyelesaiannya, r...   \n",
       "1    [nakes, murid, julidin, gurunya, aja, udah, yg...   \n",
       "2           [ruang, guru, zenius, bimbel, area, eksak]   \n",
       "3    [kebalik, kak, maksud, murid, julidin, guru, c...   \n",
       "4    [nakes, murid, julidin, gurunya, aja, udah, yg...   \n",
       "..                                                 ...   \n",
       "995   [suka, banget, ama, lagunya, letto, ruang, guru]   \n",
       "996  [kalo, negeri, awikwok, banget, dah, isinya, k...   \n",
       "997   [suka, banget, ama, lagunya, letto, ruang, guru]   \n",
       "998                                      [ruang, guru]   \n",
       "999   [suka, banget, ama, lagunya, letto, ruang, guru]   \n",
       "\n",
       "                                               stemmed  \n",
       "0    [kek, guru, julidin, murid, selesai, ruang, gu...  \n",
       "1    [nakes, murid, julidin, guru, aja, udah, yg, j...  \n",
       "2           [ruang, guru, zenius, bimbel, area, eksak]  \n",
       "3    [balik, kak, maksud, murid, julidin, guru, cum...  \n",
       "4    [nakes, murid, julidin, guru, aja, udah, yg, j...  \n",
       "..                                                 ...  \n",
       "995      [suka, banget, ama, lagu, letto, ruang, guru]  \n",
       "996  [kalo, negeri, awikwok, banget, dah, isi, kerj...  \n",
       "997      [suka, banget, ama, lagu, letto, ruang, guru]  \n",
       "998                                      [ruang, guru]  \n",
       "999      [suka, banget, ama, lagu, letto, ruang, guru]  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_kata = open('kata_positif_2.txt', 'r').readlines()\n",
    "neg_kata = open('kata_negatif_2.txt', 'r').readlines()\n",
    "\n",
    "def labeling(tokens):\n",
    "    \n",
    "    count_p = 0 #nilai positif\n",
    "    count_n = 0 #nilai negatif\n",
    "    count_ne = 0 #nilai netral\n",
    "    \n",
    "    for token in tokens:\n",
    "        for kata_pos in pos_kata:\n",
    "            if kata_pos.strip().lower() == token.lower():\n",
    "                #ind-1 digunakan untuk mencari nilai index sebelum index positifnya\n",
    "                #aku menyukai bola\n",
    "                if stemmedtexts[ind-1] in negasi:\n",
    "                    print(stemmedtexts[ind-1], kata_pos, ['negatif'])\n",
    "                    count_n += 1\n",
    "                else:\n",
    "                    print(kata_pos, ['positif'])\n",
    "                    count_p += 1\n",
    "\n",
    "        for kata_neg in neg_kata:\n",
    "            if kata_neg.strip().lower() == tweet.lower():\n",
    "                if stemmedtexts[ind-1] in negasi:\n",
    "                    print(stemmedtexts[ind-1], kata_neg, ['positif'])\n",
    "                    count_p += 1\n",
    "                else:\n",
    "                    print(kata_neg, ['negatif'])\n",
    "                    count_n += 1\n",
    "        \n",
    "        for kat_pos_neg in (pos_kata + neg_kata):\n",
    "            if kat_pos_neg.strip().lower() != tweet.lower():\n",
    "                print(stemmedtexts[ind-1], kat_pos_neg, ['netral'])\n",
    "                count_ne += 1\n",
    "    \n",
    "    sentiments.append()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36bd388c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stemmedtexts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mh:\\project\\tweepy\\main.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/project/tweepy/main.ipynb#ch0000025?line=6'>7</a>\u001b[0m negasi \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnegasi.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/project/tweepy/main.ipynb#ch0000025?line=8'>9</a>\u001b[0m \u001b[39m#fungsi menghitung sentiment setiap tweet\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/project/tweepy/main.ipynb#ch0000025?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m ind,stemmed \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(stemmedtexts):\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/project/tweepy/main.ipynb#ch0000025?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(stemmed\u001b[39m.\u001b[39mstrip())\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/project/tweepy/main.ipynb#ch0000025?line=11'>12</a>\u001b[0m     tweets \u001b[39m=\u001b[39m stemmed\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit() \u001b[39m#tokenization\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stemmedtexts' is not defined"
     ]
    }
   ],
   "source": [
    "pos_kata = open('kata_positif_2.txt', 'r').readlines()\n",
    "neg_kata = open('kata_negatif_2.txt', 'r').readlines()\n",
    "\n",
    "sentiments = [] #Membuat sebuah list menyimpan nilai sentiment\n",
    "\n",
    "#list kata-kata negasi\n",
    "negasi = open('negasi.txt', 'r').readlines()\n",
    "\n",
    "#fungsi menghitung sentiment setiap tweet\n",
    "for ind,stemmed in enumerate(stemmedtexts):\n",
    "    print(stemmed.strip())\n",
    "    tweets = stemmed.strip().split() #tokenization\n",
    "    # print(tweets)\n",
    "    \n",
    "    count_p = 0 #nilai positif\n",
    "    count_n = 0 #nilai negatif\n",
    "    count_ne = 0 #nilai netral\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        for kata_pos in pos_kata:\n",
    "            if kata_pos.strip().lower() == tweet.lower():\n",
    "                #ind-1 digunakan untuk mencari nilai index sebelum index positifnya\n",
    "                #aku menyukai bola\n",
    "                if stemmedtexts[ind-1] in negasi:\n",
    "                    print(stemmedtexts[ind-1], kata_pos, ['negatif'])\n",
    "                    count_n += 1\n",
    "                else:\n",
    "                    print(kata_pos, ['positif'])\n",
    "                    count_p += 1\n",
    "\n",
    "        for kata_neg in neg_kata:\n",
    "            if kata_neg.strip().lower() == tweet.lower():\n",
    "                if stemmedtexts[ind-1] in negasi:\n",
    "                    print(stemmedtexts[ind-1], kata_neg, ['positif'])\n",
    "                    count_p += 1\n",
    "                else:\n",
    "                    print(kata_neg, ['negatif'])\n",
    "                    count_n += 1\n",
    "        \n",
    "        for kat_pos_neg in (pos_kata + neg_kata):\n",
    "            if kat_pos_neg.strip().lower() != tweet.lower():\n",
    "                print(stemmedtexts[ind-1], kat_pos_neg, ['netral'])\n",
    "                count_ne += 1\n",
    "    \n",
    "    sentiments.append()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcf67f61d93bb807738c728a2d36bcd352b61f91fdc0746bde934977bba04043"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
