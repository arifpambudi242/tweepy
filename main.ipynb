{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd9ca35",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analisys menggunakan metode A NAIVE BAYES CLASSIFIER (NBC)\n",
    "### 1.Case Folding:\n",
    "Case folding dilakukan untuk\n",
    "mengubah setiap karakter didalam teks menjadi huruf\n",
    "kecil. Tidak semua kata dalam teks konsisten dalam\n",
    "penggunaan huruf kapital disinilah tujuan dilakukan case\n",
    "folding untuk mengkonversi setiap karakter dalam kata\n",
    "menjadi huruf kecil.\n",
    "### 2.Tokenisasi: \n",
    "Tokenisasi merupakan proses\n",
    "pemecahan kata pada suatu teks ke dalam satuan kata.\n",
    "Tokenisasi dilakukan untuk menghasilkan kumpulan kata\n",
    "yang berdiri sendiri, tokenisasi memecah teks yang\n",
    "semula berupa kalimat menjadi kata-kata. tokenisasi\n",
    "menghilangkan delimeter seperti titik (.), koma (,), spasi,\n",
    "dan karakter angka yang ada pada kata tersebut.\n",
    "Dalam penelitian ini tokenisasi dilakukan untuk\n",
    "memecah kata, serta melakukan penghapusan delimeter\n",
    "beserta karakter angka bersama tweet entity seperti\n",
    "hashtag, retweet dan mention.\n",
    "### 3.Filtering: \n",
    "Filtering merupakan proses dalam text\n",
    "preprocessing setelah tokenisasi, filtering dilakukan untuk\n",
    "untuk mengambil kata penting hasil tokenisasi. Pada tahap\n",
    "filtering kata akan ditentukan apakah akan digunakan atau \n",
    "dibuang. Proses dalam filtering dalam membuang katakata yang tidak digunakan atau stopword terdapat dalam\n",
    "bag of words stoplist.\n",
    "Stopword merupakan daftar kata-kata yang tidak\n",
    "mempresentasikan isi dari suatu dokumen teks, stopword\n",
    "dilakukan untuk meghilangkan kata atau term yang tidak\n",
    "memiliki arti. Daftar stoplist akan dibuat sebelum\n",
    "melakukan proses stopword removal, jika kata-kata\n",
    "terdapat dalam daftar stoplist, maka kata tersebut akan\n",
    "dihapus, sehingga kata-kata yang tersisa akan dianggap\n",
    "kata yang mencirikan isi suatu dokumen.\n",
    "### 4.Stemming: \n",
    "Stemming merupakan proses mengubah\n",
    "kata menjadi bentuk dasarnya. Stemming dilakukan untuk\n",
    "meyeragamkan bentuk kata. Tujuan dari proses stemming\n",
    "adalah menghilangkan imbuhan-imbuhan baik itu berupa\n",
    "prefiks, sufiks, maupun konfiks yang ada pada setiap kata. \n",
    "Stemming dalam penelitian ini dilakukan berdasarkan\n",
    "aturan morfologi bahasa Indonesia.\n",
    "\n",
    "\n",
    "### berikut adalah langka-langkahnya:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51ef51",
   "metadata": {},
   "source": [
    "### 1.Install Library(module) yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136490e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %pip install tweepy\n",
    "# %pip install Sastrawi\n",
    "# %pip install numpy\n",
    "# %pip install sklearn\n",
    "# %pip install textblob\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81aea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARERTOKEN = 'AAAAAAAAAAAAAAAAAAAAAJQrYQEAAAAA1BtlexYIrHRZvqkz6TEOraEC%2B0k%3D5cOp6U7ytEMpcTDctDQWVl6HFd0Y28pxhDnTGyHA9KiiC1MVCF'\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARERTOKEN)\n",
    "\n",
    "query = '\"Elon Musk\" lang:id'\n",
    "\n",
    "# get data max 100\n",
    "responses = client.search_recent_tweets(query=query, max_results=100, tweet_fields=['created_at'])\n",
    "tweet100 = [tweet for tweet in responses.data]\n",
    "\n",
    "# get max 1000\n",
    "tweettexts = [tweet.text for tweet in tweepy.Paginator(client.search_recent_tweets, query=query, max_results=100).flatten(limit=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edee1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fece5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'text' : tweettexts\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(f\"crawling.csv\", mode='w', index=False, header=data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa7fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @banyuluynad: Cita2 pengen kayak warren buf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tp rasanya taurus ni mmg ngam ngan cancer lah....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @swahilitimes: Jack Ma na Elon Musk wakijad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @ayuazizz: Amber Heard punya gila, dia siap...\n",
       "1  RT @ayuazizz: Amber Heard punya gila, dia siap...\n",
       "2  RT @banyuluynad: Cita2 pengen kayak warren buf...\n",
       "3  tp rasanya taurus ni mmg ngam ngan cancer lah....\n",
       "4  RT @swahilitimes: Jack Ma na Elon Musk wakijad..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('crawling.csv', encoding='unicode_escape')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2058c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text\n",
    "def textcleaner(text):\n",
    "    new_text = str(text)\n",
    "    \n",
    "    # remove old style retweet text \"RT\"\n",
    "    new_text = re.sub(r'^RT\\s+', '', new_text)\n",
    "    \n",
    "    # remove username\n",
    "    new_text = re.sub(r'@([A-Za-z0-9_]+)', '', new_text)\n",
    "\n",
    "    # remove hyperlinks\n",
    "    new_text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', new_text)\n",
    "\n",
    "    # remove invalid character\n",
    "    new_text = re.sub(\"[^A-Za-z\" \"]+\", \" \", new_text)\n",
    "    \n",
    "    new_text    = re.sub(r'\\b\\w(1,2)\\b',' ', new_text) #menghilangkan 2 kata\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8447bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caselower(sentences):\n",
    "    return sentences.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602e90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenmaker(sentences):\n",
    "    return sentences.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b28e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Removal\n",
    "stopword = nltk.corpus.stopwords.words(\"indonesian\")\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be246c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05eeef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labeler\n",
    "\n",
    "pos_kata = [pos.strip() for pos in open('kata_positif_2.txt', 'r').readlines()]\n",
    "neg_kata = [neg.strip() for neg in open('kata_negatif_2.txt', 'r').readlines()]\n",
    "\n",
    "#list kata-kata negasi\n",
    "negasi = [neg.strip() for neg in open('negasi.txt', 'r').readlines()]\n",
    "\n",
    "\n",
    "def labeling(stemmed):\n",
    "    count_pos = 0\n",
    "    count_neg = 0\n",
    "    for ind, stem in enumerate(stemmed):\n",
    "        if stem.strip() in pos_kata:\n",
    "            if stemmed[ind-1].strip() in negasi:\n",
    "                count_neg += 1\n",
    "            else:\n",
    "                count_pos += 1\n",
    "        elif stem.strip() in neg_kata:\n",
    "            if stemmed[ind-1].strip() in negasi:\n",
    "                count_pos += 1\n",
    "            else:\n",
    "                count_neg += 1\n",
    "\n",
    "    return 'NETRAL' if count_pos == count_neg else 'POSITIF' if count_pos > count_neg else 'NEGATIF'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b013e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text\n",
    "df['clean_text'] = df['text'].apply(lambda x : textcleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "067846e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cover ke lower case\n",
    "df['lower'] = df['clean_text'].apply(lambda x : caselower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f02b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "df['token'] = df['lower'].apply(lambda x : tokenmaker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074e5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopword removing\n",
    "df[\"stop_removed\"] = df['token'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56bfe6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming selesai!\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "df[\"stemmed\"] = df['stop_removed'].apply(lambda x: stemming(x))\n",
    "print(\"Stemming selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a27497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lower</th>\n",
       "      <th>token</th>\n",
       "      <th>stop_removed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @banyuluynad: Cita2 pengen kayak warren buf...</td>\n",
       "      <td>Cita pengen kayak warren buffett jeff bezos e...</td>\n",
       "      <td>cita pengen kayak warren buffett jeff bezos e...</td>\n",
       "      <td>[cita, pengen, kayak, warren, buffett, jeff, b...</td>\n",
       "      <td>[cita, pengen, kayak, warren, buffett, jeff, b...</td>\n",
       "      <td>[cita, ken, kayak, warren, buffett, jeff, bezo...</td>\n",
       "      <td>POSITIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tp rasanya taurus ni mmg ngam ngan cancer lah....</td>\n",
       "      <td>tp rasanya taurus ni mmg ngam ngan cancer lah ...</td>\n",
       "      <td>tp rasanya taurus ni mmg ngam ngan cancer lah ...</td>\n",
       "      <td>[tp, rasanya, taurus, ni, mmg, ngam, ngan, can...</td>\n",
       "      <td>[tp, taurus, ni, mmg, ngam, ngan, cancer, libr...</td>\n",
       "      <td>[tp, taurus, ni, mmg, ngam, ngan, cancer, libr...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @swahilitimes: Jack Ma na Elon Musk wakijad...</td>\n",
       "      <td>Jack Ma na Elon Musk wakijadiliana kati ya bi...</td>\n",
       "      <td>jack ma na elon musk wakijadiliana kati ya bi...</td>\n",
       "      <td>[jack, ma, na, elon, musk, wakijadiliana, kati...</td>\n",
       "      <td>[jack, ma, na, elon, musk, wakijadiliana, kati...</td>\n",
       "      <td>[jack, ma, na, elon, musk, wakijadiliana, kati...</td>\n",
       "      <td>NETRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>RT @ayuazizz: Amber Heard punya gila, dia siap...</td>\n",
       "      <td>Amber Heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>amber heard punya gila dia siap bekukan benih...</td>\n",
       "      <td>[amber, heard, punya, gila, dia, siap, bekukan...</td>\n",
       "      <td>[amber, heard, gila, bekukan, benih, elon, mus...</td>\n",
       "      <td>[amber, heard, gila, beku, benih, elon, musk, ...</td>\n",
       "      <td>NEGATIF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "1    RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "2    RT @banyuluynad: Cita2 pengen kayak warren buf...   \n",
       "3    tp rasanya taurus ni mmg ngam ngan cancer lah....   \n",
       "4    RT @swahilitimes: Jack Ma na Elon Musk wakijad...   \n",
       "..                                                 ...   \n",
       "995  RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "996  RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "997  RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "998  RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "999  RT @ayuazizz: Amber Heard punya gila, dia siap...   \n",
       "\n",
       "                                            clean_text  \\\n",
       "0     Amber Heard punya gila dia siap bekukan benih...   \n",
       "1     Amber Heard punya gila dia siap bekukan benih...   \n",
       "2     Cita pengen kayak warren buffett jeff bezos e...   \n",
       "3    tp rasanya taurus ni mmg ngam ngan cancer lah ...   \n",
       "4     Jack Ma na Elon Musk wakijadiliana kati ya bi...   \n",
       "..                                                 ...   \n",
       "995   Amber Heard punya gila dia siap bekukan benih...   \n",
       "996   Amber Heard punya gila dia siap bekukan benih...   \n",
       "997   Amber Heard punya gila dia siap bekukan benih...   \n",
       "998   Amber Heard punya gila dia siap bekukan benih...   \n",
       "999   Amber Heard punya gila dia siap bekukan benih...   \n",
       "\n",
       "                                                 lower  \\\n",
       "0     amber heard punya gila dia siap bekukan benih...   \n",
       "1     amber heard punya gila dia siap bekukan benih...   \n",
       "2     cita pengen kayak warren buffett jeff bezos e...   \n",
       "3    tp rasanya taurus ni mmg ngam ngan cancer lah ...   \n",
       "4     jack ma na elon musk wakijadiliana kati ya bi...   \n",
       "..                                                 ...   \n",
       "995   amber heard punya gila dia siap bekukan benih...   \n",
       "996   amber heard punya gila dia siap bekukan benih...   \n",
       "997   amber heard punya gila dia siap bekukan benih...   \n",
       "998   amber heard punya gila dia siap bekukan benih...   \n",
       "999   amber heard punya gila dia siap bekukan benih...   \n",
       "\n",
       "                                                 token  \\\n",
       "0    [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "1    [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "2    [cita, pengen, kayak, warren, buffett, jeff, b...   \n",
       "3    [tp, rasanya, taurus, ni, mmg, ngam, ngan, can...   \n",
       "4    [jack, ma, na, elon, musk, wakijadiliana, kati...   \n",
       "..                                                 ...   \n",
       "995  [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "996  [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "997  [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "998  [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "999  [amber, heard, punya, gila, dia, siap, bekukan...   \n",
       "\n",
       "                                          stop_removed  \\\n",
       "0    [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "1    [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "2    [cita, pengen, kayak, warren, buffett, jeff, b...   \n",
       "3    [tp, taurus, ni, mmg, ngam, ngan, cancer, libr...   \n",
       "4    [jack, ma, na, elon, musk, wakijadiliana, kati...   \n",
       "..                                                 ...   \n",
       "995  [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "996  [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "997  [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "998  [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "999  [amber, heard, gila, bekukan, benih, elon, mus...   \n",
       "\n",
       "                                               stemmed sentiment  \n",
       "0    [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "1    [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "2    [cita, ken, kayak, warren, buffett, jeff, bezo...   POSITIF  \n",
       "3    [tp, taurus, ni, mmg, ngam, ngan, cancer, libr...   NEGATIF  \n",
       "4    [jack, ma, na, elon, musk, wakijadiliana, kati...    NETRAL  \n",
       "..                                                 ...       ...  \n",
       "995  [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "996  [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "997  [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "998  [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "999  [amber, heard, gila, beku, benih, elon, musk, ...   NEGATIF  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labelling sentiment\n",
    "df[\"sentiment\"] = df['stemmed'].apply(lambda x: labeling(x))\n",
    "df.to_csv(f\"labeled.csv\", mode='w', index=False, header=False)\n",
    "df.head(df.size)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcf67f61d93bb807738c728a2d36bcd352b61f91fdc0746bde934977bba04043"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
